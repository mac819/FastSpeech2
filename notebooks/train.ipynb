{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c4d0eb-88cf-499a-b35f-ebecc47d3aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0609 15:57:38.831000 60845 site-packages/torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from audioml.fastspeech.model import Text2Mel\n",
    "from audioml.dataset.feature_dataset import SpeechFeatureDataset\n",
    "from audioml.processing.text_speech_alignment import TTSTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3607db8-1c64-4626-96c4-7855180c18cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47dc23d3-0ed0-452d-8f78-7da69d6916a9",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d377fb-3942-42db-9529-fb361b922a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mayankanand/Documents/audio/audio/audioml/config.yaml\n"
     ]
    }
   ],
   "source": [
    "os.listdir(Path(os.getcwd()).parent / 'audioml')\n",
    "config_path = Path(os.getcwd()).parent / 'audioml' / 'config.yaml'\n",
    "print(config_path)\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7873ee7-8b70-450d-a297-1f1330f88cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_DIR = Path(os.getcwd()).parent / 'data' / 'processed' / 'lj_speech_feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be168702-fdc5-460f-b38f-0b12f583d9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fec074-1557-4657-9540-30f8faa3ac8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2378b946-507b-4b85-bf04-6ffe66e29d2e",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a757c6e2-e877-47c7-9c60-4fd953492d1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 16:04:01 nemo_logging:393] Found existing object /Users/mayankanand/.cache/torch/NeMo/NeMo_2.3.1/Aligner/5b0d70eb6a09c1a8470b745034a1a00b/Aligner.nemo.\n",
      "[NeMo I 2025-06-09 16:04:01 nemo_logging:393] Re-using file from: /Users/mayankanand/.cache/torch/NeMo/NeMo_2.3.1/Aligner/5b0d70eb6a09c1a8470b745034a1a00b/Aligner.nemo\n",
      "[NeMo I 2025-06-09 16:04:01 nemo_logging:393] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: INFO     :: Creating ClassifyFst grammars.\n",
      "[NeMo W 2025-06-09 16:04:15 nemo_logging:405] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n",
      "[NeMo W 2025-06-09 16:04:15 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.torch.data.TTSDataset\n",
      "      manifest_filepath: /data3/LJSpeech/nvidia_ljspeech_train.json\n",
      "      sample_rate: 22050\n",
      "      sup_data_path: /data3/LJSpeech/align_supplementary/\n",
      "      sup_data_types:\n",
      "      - align_prior_matrix\n",
      "      n_fft: 1024\n",
      "      win_length: 1024\n",
      "      hop_length: 256\n",
      "      window: hann\n",
      "      n_mels: 80\n",
      "      lowfreq: 0\n",
      "      highfreq: 8000\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      ignore_file: null\n",
      "      trim: false\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: true\n",
      "      batch_size: 64\n",
      "      num_workers: 4\n",
      "      pin_memory: false\n",
      "    \n",
      "[NeMo W 2025-06-09 16:04:15 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.torch.data.TTSDataset\n",
      "      manifest_filepath: /data3/LJSpeech/nvidia_ljspeech_val.json\n",
      "      sample_rate: 22050\n",
      "      sup_data_path: /data3/LJSpeech/align_supplementary/\n",
      "      sup_data_types:\n",
      "      - align_prior_matrix\n",
      "      n_fft: 1024\n",
      "      win_length: 1024\n",
      "      hop_length: 256\n",
      "      window: hann\n",
      "      n_mels: 80\n",
      "      lowfreq: 0\n",
      "      highfreq: 8000\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      ignore_file: null\n",
      "      trim: false\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 64\n",
      "      num_workers: 1\n",
      "      pin_memory: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 16:04:15 nemo_logging:393] PADDING: 1\n",
      "[NeMo I 2025-06-09 16:04:15 nemo_logging:393] Model AlignerModel was successfully restored from /Users/mayankanand/.cache/torch/NeMo/NeMo_2.3.1/Aligner/5b0d70eb6a09c1a8470b745034a1a00b/Aligner.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: INFO     :: Creating ClassifyFst grammars.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "feature_dataset = SpeechFeatureDataset(\n",
    "    feature_dir=FEATURE_DIR,\n",
    "    batch_size=batch_size,\n",
    "    sort=True,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4883e519-10b2-428a-a1c5-bbfbda5ca9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_size = 8\n",
    "shuffle=True\n",
    "feature_dataloader = DataLoader(\n",
    "    feature_dataset,\n",
    "    batch_size=group_size * batch_size,\n",
    "    shuffle=shuffle,\n",
    "    collate_fn=feature_dataset.collate_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27bb1f3c-53b0-451f-8651-317a3e0dbf1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Length: [105, 118, 60, 61, 81, 89, 106, 53, 56, 111, 118, 65, 112, 79, 127, 85, 108, 97, 71, 106, 107, 58, 73, 27, 143, 122, 87, 95, 101, 129, 46, 92]\n",
      "Sorted IDX: [24 29 14 25  1 10 12  9 16 20  6 19  0 28 17 27 31  5 26 15  4 13 22 18\n",
      " 11  3  2 21  8  7 30 23]\n",
      "idx_arr: [[24, 29, 14, 25], [1, 10, 12, 9], [16, 20, 6, 19], [0, 28, 17, 27], [31, 5, 26, 15], [4, 13, 22, 18], [11, 3, 2, 21], [8, 7, 30, 23]]\n",
      "[\"Oswald's known actions in the building immediately after the assassination are consistent with his having been at the southeast corner window of the sixth floor\", 'Courvoisier wished to commit suicide in Newgate, but was prevented by the vigilant supervision to which he was subjected while in jail.', \"the firm's paper went down further and further in value; an application to the Committee of Bankers for assistance was peremptorily refused,\", 'Both Director Hoover and Belmont expressed to the Commission the great concern of the FBI, which is shared by the Secret Service,']\n",
      "[143, 129, 127, 122]\n",
      "['The books and journals he was to keep were minutely specified, and his constant presence in or near the jail was insisted upon.', 'This, however, is probably not a source of vital energy, but only contributes to the maintenance of the body temperature.', 'but upon this forged and false conveyance William Roupell, who had already embarked upon a career of wild extravagance,', 'even in the case of the green plant, which in the dark absorbs oxygen and gives out carbonic acid like any animal.']\n",
      "[118, 118, 112, 111]\n",
      "['All three men were committed for trial, although Edwards wished to exculpate the others as having only acted under his order.', 'and with the concurrence of the other authority, and on payment. A few provisos governed these rather extensive powers.', 'with only a short interval between it and the wall, supported by a horizontal iron railing with upright points;', 'Oswald said that this was not true. Oswald denied that he had a rifle wrapped up in a blanket in the Paine garage.']\n",
      "[108, 107, 106, 106]\n",
      "['Desired by both the President and the public, it is an indispensable means of communication between the two.', 'A number of people who resembled some of those in the photographs were placed under surveillance at the Trade Mart.', 'It is unlikely that any of the police officers referred to Oswald as a suspect in the assassination.', 'the germs, more or less developed, of contagious disease. \"Caravans,\" the forerunners of the prison vans,']\n",
      "[105, 101, 97, 95]\n",
      "['Secret Service men accompanied the President and his family to their vacation home in Massachusetts', 'Mr. Nixon advised the Commission that the only time he was in Dallas in nineteen sixty-three', 'were governed by rules which they themselves had framed, and under which subscriptions were levied', 'In contrast, the Vice Presidential vehicle, although not specially designed for that purpose,']\n",
      "[92, 89, 87, 85]\n",
      "['She did not speak to him when she joined him there, although she thought that he was still awake.', 'Strangers were now excluded, but the sheriffs attended in state, wearing their gold chains,', '(four) carried the rifle into the Depository Building, concealed in the bag;', 'Giovanni Lanni, the Italian boy who murdered a Frenchwoman in the Haymarket,']\n",
      "[81, 79, 73, 71]\n",
      "['I speak, therefore, tonight, to and of the American people as a whole.', 'It has been discussed and approved by many persons of high authority', 'Simple as this proposition is, it is necessary to be stated,', 'Such an extravagant defense did not weigh with judge or jury;']\n",
      "[65, 61, 60, 58]\n",
      "[\"I am surprised that he didn't do something worse, end quote.\", 'After he brought the rifle home, then, he showed you the book?', 'were not altogether creditable to the Government.', 'Assassination a Federal Crime']\n",
      "[56, 53, 46, 27]\n"
     ]
    }
   ],
   "source": [
    "for batchs in feature_dataloader:\n",
    "    for batch in batchs:\n",
    "        print(batch['raw_text'])\n",
    "        print(batch['token_length'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3b0869e-2906-4666-9916-4a36b381e940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148, 139, 132, 130]\n",
      "[124, 124, 124, 123]\n",
      "[121, 116, 116, 115]\n",
      "[112, 111, 110, 108]\n",
      "[106, 103, 101, 99]\n",
      "[98, 95, 89, 89]\n",
      "[86, 78, 73, 70]\n",
      "[53, 53, 44, 21]\n"
     ]
    }
   ],
   "source": [
    "for batch in batchs:\n",
    "    print(batch['token_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088723a8-170e-48b5-9930-136cea0d990f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6ebd370-62af-404a-9b67-e7b28212000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_length = [111, 45, 119, 68, 58, 129, 100, 121, 133, 114, 140, 47, 104, 101, 94, 128, 78, 71, 125, 112, 45, 33, 119, 67, 92, 117, 109, 57, 57, 100, 118, 132]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20f5dfb2-ed18-48fd-adc3-c4e7b27a436b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  8, 31,  5, 15, 18,  7,  2, 22, 30, 25,  9, 19,  0, 26, 12, 13,\n",
       "        6, 29, 14, 24, 16, 17,  3, 23,  4, 27, 28, 11, 20,  1, 21])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(token_length)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02b9c63a-f1f8-4a0c-806c-02a3b742eafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_length[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9355136f-709d-40f9-bfeb-07a10843a8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "962a5468-91dd-4855-bed2-c3a756ac23cc",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13d23be-0f8c-41e7-9c13-b83e0b6a2cfe",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4537fcb3-0ff1-454e-afac-4a1105050cab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-08 10:27:58 nemo_logging:393] Found existing object /Users/mayankanand/.cache/torch/NeMo/NeMo_2.3.1/Aligner/5b0d70eb6a09c1a8470b745034a1a00b/Aligner.nemo.\n",
      "[NeMo I 2025-06-08 10:27:58 nemo_logging:393] Re-using file from: /Users/mayankanand/.cache/torch/NeMo/NeMo_2.3.1/Aligner/5b0d70eb6a09c1a8470b745034a1a00b/Aligner.nemo\n",
      "[NeMo I 2025-06-08 10:27:58 nemo_logging:393] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: INFO     :: Creating ClassifyFst grammars.\n",
      "[NeMo W 2025-06-08 10:28:11 nemo_logging:405] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n",
      "[NeMo W 2025-06-08 10:28:11 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.torch.data.TTSDataset\n",
      "      manifest_filepath: /data3/LJSpeech/nvidia_ljspeech_train.json\n",
      "      sample_rate: 22050\n",
      "      sup_data_path: /data3/LJSpeech/align_supplementary/\n",
      "      sup_data_types:\n",
      "      - align_prior_matrix\n",
      "      n_fft: 1024\n",
      "      win_length: 1024\n",
      "      hop_length: 256\n",
      "      window: hann\n",
      "      n_mels: 80\n",
      "      lowfreq: 0\n",
      "      highfreq: 8000\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      ignore_file: null\n",
      "      trim: false\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: true\n",
      "      batch_size: 64\n",
      "      num_workers: 4\n",
      "      pin_memory: false\n",
      "    \n",
      "[NeMo W 2025-06-08 10:28:11 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.torch.data.TTSDataset\n",
      "      manifest_filepath: /data3/LJSpeech/nvidia_ljspeech_val.json\n",
      "      sample_rate: 22050\n",
      "      sup_data_path: /data3/LJSpeech/align_supplementary/\n",
      "      sup_data_types:\n",
      "      - align_prior_matrix\n",
      "      n_fft: 1024\n",
      "      win_length: 1024\n",
      "      hop_length: 256\n",
      "      window: hann\n",
      "      n_mels: 80\n",
      "      lowfreq: 0\n",
      "      highfreq: 8000\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      ignore_file: null\n",
      "      trim: false\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 64\n",
      "      num_workers: 1\n",
      "      pin_memory: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-08 10:28:11 nemo_logging:393] PADDING: 1\n",
      "[NeMo I 2025-06-08 10:28:12 nemo_logging:393] Model AlignerModel was successfully restored from /Users/mayankanand/.cache/torch/NeMo/NeMo_2.3.1/Aligner/5b0d70eb6a09c1a8470b745034a1a00b/Aligner.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: INFO     :: Creating ClassifyFst grammars.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = TTSTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eede549-618a-4698-8820-df5488e5c629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70af5dd3-9142-4316-bc7f-ed16b894ff6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbbbfb64-aff6-4748-ab54-709fb7c2c2ed",
   "metadata": {},
   "source": [
    "## Text2Mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "608ab4e9-fca2-4690-b82a-1693a916373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2mel = Text2Mel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd7332-f743-4be8-a959-194f239502b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e8e42bc-99d2-48ff-87f6-f6e2d76b173d",
   "metadata": {},
   "source": [
    "# Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f563302-853a-41d8-8f52-53161ce4edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "phones = tokenizer.batch_tokenize(batch['raw_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dad4ab64-b2bb-4a85-9ce5-1b52c70cbd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, src_mask, duration = phones['input_ids'], phones['mask_ids'], batch['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e94ceb4b-6e30-41d9-a2ae-63fd46e02c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2mel_output = text2mel(input_ids, src_mask, train=True, gt_duration=duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ea7223d-39b3-4938-92e1-025b667d2cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mel_spec', 'mel_mask', 'log_duration', 'duration', 'pitch', 'energy'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2mel_output.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87174d7-f496-422a-ad40-8f35aa8489db",
   "metadata": {},
   "source": [
    "### Pitch Predicted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d30a9c1e-992f-4a1a-9dd8-826789e99b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_output = text2mel_output['pitch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe6f8f14-c786-43a5-9681-54a122e7a34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitch Spectrogram: torch.Size([8, 616, 10])\n",
      "Pitch Mean:        torch.Size([8])\n",
      "Pitch std:         torch.Size([8])\n",
      "Pitch F0:          torch.Size([8, 616])\n"
     ]
    }
   ],
   "source": [
    "pitch_spec = pitch_output['pitch_spectrogram']\n",
    "pitch_mean = pitch_output['pitch_mean']\n",
    "pitch_std = pitch_output['pitch_std']\n",
    "pitch_f0 = pitch_output['reconstructed_f0'] # This is not notmalized\n",
    "\n",
    "# print(f\"===== Pitch Predicted Features =====\")\n",
    "print(f\"Pitch Spectrogram: {pitch_spec.shape}\")\n",
    "print(f\"Pitch Mean:        {pitch_mean.shape}\")\n",
    "print(f\"Pitch std:         {pitch_std.shape}\")\n",
    "print(f\"Pitch F0:          {pitch_f0.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ed9016-5434-4585-a37c-16bda35c23c7",
   "metadata": {},
   "source": [
    "### Pitch Target/Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a63efd4b-b42e-4ef7-890a-edf3426c4eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.2549, 5.1765, 5.4370, 5.3852, 5.2531, 5.3193, 5.3611, 5.2811])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(batch['pitch_contour_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbd0d102-b23b-4956-8330-fd6e1011f18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitch Spectrogram: torch.Size([8, 616, 10])\n",
      "Pitch Mean:        torch.Size([8])\n",
      "Pitch STD:         torch.Size([8])\n",
      "Pitch F0:          torch.Size([8, 616])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pitch Spectrogram: {batch['pitch_spectrogram'].shape}\")\n",
    "print(f\"Pitch Mean:        {torch.tensor(batch['pitch_contour_mean']).shape}\")\n",
    "print(f\"Pitch STD:         {torch.tensor(batch['pitch_contour_std']).shape}\")\n",
    "print(f\"Pitch F0:          {torch.tensor(batch['pitch_contour']).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c6ea2b-ee3f-4f5a-9655-e10ef9cfd938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "326ccbbc-dd68-4179-8ec6-da05ed4dee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "mae_loss = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09627158-0310-460d-b010-30463164ac8d",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381a5419-fbfc-41ea-b6d4-363472a34ad9",
   "metadata": {},
   "source": [
    "**Targets/Labels**\n",
    "1. Mel-Spectrogram\n",
    "2. Duration (log_duration)\n",
    "3. Pitch-Spectrogram\n",
    "4. Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf18980-bff2-493d-b756-c00b228c95f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastSpeech2Loss(nn.Module):\n",
    "    \"\"\" FastSpeech2 Loss \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FastSpeech2Loss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.mae_loss = nn.L1Loss()\n",
    "\n",
    "    def forward(self, inputs, predictions, src_mask):\n",
    "        # Inputs (Ground Truth) / Target\n",
    "        # Duration Target\n",
    "        log_duration_target = torch.log(torch.clamp(inputs['duration'], min=1.0)).masked_fill(src_mask.bool(), 0)\n",
    "        # Mel-Spectrogram Target\n",
    "        mel_spec_target = inputs['mel_spectrogram']\n",
    "        # Pitch Target\n",
    "        pitch_spec_target = inputs['pitch_spectrogram']\n",
    "        pitch_contour_target = inputs['pitch_contour']\n",
    "        pitch_mean_target = inputs['pitch_contour_mean']\n",
    "        pitch_std_target = inputs['pitch_contour_std']\n",
    "        # Energy Target\n",
    "        energy_target = inputs['energy']\n",
    "        \n",
    "        # Predictions\n",
    "        # Mel-Spectrogram Prediction\n",
    "        pred_mel_spec = predictions['mel_spec']\n",
    "        mel_mask = predictions['mel_mask']\n",
    "        # Pitch Feature Prediction\n",
    "        pitch_predictions = predictions['pitch']\n",
    "        pred_pitch_spec = pitch_predictions['pitch_spectrogram']\n",
    "        pred_f0 = pitch_predictions['reconstructed_f0']\n",
    "        pred_pitch_mean = pitch_predictions['pitch_contour_mean']\n",
    "        pred_pitch_std = pitch_predictions['pitch_contour_std']\n",
    "        # Energy Prediction\n",
    "        energy_predictions = predictions['energy']\n",
    "        pred_energy = energy_predictions['raw_energy']\n",
    "        # Duration Prediction\n",
    "        pred_log_duration = predictions['log_duration']\n",
    "        \n",
    "        # src_masks = ~src_masks\n",
    "        # mel_masks = ~mel_masks\n",
    "        # log_duration_targets = torch.log(duration_targets.float() + 1)\n",
    "        mel_spec_target = mel_spec_target[:, :mel_masks.shape[1], :]\n",
    "        mel_masks = mel_masks[:, :mel_masks.shape[1]]\n",
    "\n",
    "        log_duration_targets.requires_grad = False\n",
    "        mel_spec_target.requires_grad = False\n",
    "        pitch_spec_target.requires_grad = False\n",
    "        pitch_contour_target.requires_grad = False\n",
    "        pitch_mean_target.requires_grad = False\n",
    "        pitch_std_target.requires_grad = False\n",
    "        energy_target.requires_grad = False\n",
    "        \n",
    "        # Loss Calculation\n",
    "        # Mel-Spectrogram loss\n",
    "        mel_loss = self.mae_loss(pred_mel_spec, mel_spec_target)\n",
    "        # Pitch Loss\n",
    "        pitch_spectrogram_loss = self.mse_loss(pred_pitch_spec, pitch_spec_target)\n",
    "        pitch_mean_loss = self.mse_loss(pred_pitch_mean, pitch_mean_target)\n",
    "        pitch_std_loss = self.mse_loss(pred_pitch_std, pitch_std_target)\n",
    "        # Energy Loss\n",
    "        energy_loss = self.mse_loss(pred_energy, energy_target)\n",
    "        # Duration Loss\n",
    "        duration_loss = self.mse_loss(pred_log_duration, log_duration_target)\n",
    "\n",
    "        total_loss = (\n",
    "            mel_loss + duration_loss + pitch_spectrogram_loss + pitch_mean_loss + pitch_std_loss + energy_loss\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            total_loss,\n",
    "            mel_loss,\n",
    "            duration_loss,\n",
    "            pitch_spectrogram_loss,\n",
    "            pitch_mean_loss,\n",
    "            pitch_std_loss,\n",
    "            energy_loss\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5c2619-379c-4fbf-9712-0cdcd2095c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51d796aa-d739-4194-8c8b-ced33fe59106",
   "metadata": {},
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7adb8078-8aaf-417b-90e3-977aa4917c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d52a57-1ca1-48ff-876c-6b9c1c2d03f4",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee81c4d5-0812-42da-a3da-5d8bd15d6a40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 4\n",
    "total_steps = 10000\n",
    "\n",
    "# Load Dataset\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356101fc-9b88-45bb-b6d9-3cb35acfda12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 15:57:54 nemo_logging:393] Found existing object /Users/mayankanand/.cache/torch/NeMo/NeMo_2.3.1/Aligner/5b0d70eb6a09c1a8470b745034a1a00b/Aligner.nemo.\n",
      "[NeMo I 2025-06-09 15:57:54 nemo_logging:393] Re-using file from: /Users/mayankanand/.cache/torch/NeMo/NeMo_2.3.1/Aligner/5b0d70eb6a09c1a8470b745034a1a00b/Aligner.nemo\n",
      "[NeMo I 2025-06-09 15:57:54 nemo_logging:393] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: INFO     :: Creating ClassifyFst grammars.\n",
      "[NeMo W 2025-06-09 15:58:07 nemo_logging:405] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n",
      "[NeMo W 2025-06-09 15:58:07 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.torch.data.TTSDataset\n",
      "      manifest_filepath: /data3/LJSpeech/nvidia_ljspeech_train.json\n",
      "      sample_rate: 22050\n",
      "      sup_data_path: /data3/LJSpeech/align_supplementary/\n",
      "      sup_data_types:\n",
      "      - align_prior_matrix\n",
      "      n_fft: 1024\n",
      "      win_length: 1024\n",
      "      hop_length: 256\n",
      "      window: hann\n",
      "      n_mels: 80\n",
      "      lowfreq: 0\n",
      "      highfreq: 8000\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      ignore_file: null\n",
      "      trim: false\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: true\n",
      "      batch_size: 64\n",
      "      num_workers: 4\n",
      "      pin_memory: false\n",
      "    \n",
      "[NeMo W 2025-06-09 15:58:07 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.torch.data.TTSDataset\n",
      "      manifest_filepath: /data3/LJSpeech/nvidia_ljspeech_val.json\n",
      "      sample_rate: 22050\n",
      "      sup_data_path: /data3/LJSpeech/align_supplementary/\n",
      "      sup_data_types:\n",
      "      - align_prior_matrix\n",
      "      n_fft: 1024\n",
      "      win_length: 1024\n",
      "      hop_length: 256\n",
      "      window: hann\n",
      "      n_mels: 80\n",
      "      lowfreq: 0\n",
      "      highfreq: 8000\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      ignore_file: null\n",
      "      trim: false\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 64\n",
      "      num_workers: 1\n",
      "      pin_memory: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 15:58:07 nemo_logging:393] PADDING: 1\n",
      "[NeMo I 2025-06-09 15:58:07 nemo_logging:393] Model AlignerModel was successfully restored from /Users/mayankanand/.cache/torch/NeMo/NeMo_2.3.1/Aligner/5b0d70eb6a09c1a8470b745034a1a00b/Aligner.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: INFO     :: Creating ClassifyFst grammars.\n"
     ]
    }
   ],
   "source": [
    "feature_dataset = SpeechFeatureDataset(\n",
    "    feature_dir=FEATURE_DIR,\n",
    "    batch_size=batch_size,\n",
    "    sort=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "group_size = 4\n",
    "shuffle=True\n",
    "feature_dataloader = DataLoader(\n",
    "    feature_dataset,\n",
    "    batch_size=group_size * batch_size,\n",
    "    shuffle=shuffle,\n",
    "    collate_fn=feature_dataset.collate_function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf711577-b4fa-4a76-aa32-23e39a0ba77f",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d301f818-6a8a-4362-a2d0-de62781f61b8",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48edfd73-9322-44fc-9dcb-a1d047bd4f01",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 15:58:30 nemo_logging:393] Found existing object /Users/mayankanand/.cache/torch/NeMo/NeMo_2.3.1/Aligner/5b0d70eb6a09c1a8470b745034a1a00b/Aligner.nemo.\n",
      "[NeMo I 2025-06-09 15:58:30 nemo_logging:393] Re-using file from: /Users/mayankanand/.cache/torch/NeMo/NeMo_2.3.1/Aligner/5b0d70eb6a09c1a8470b745034a1a00b/Aligner.nemo\n",
      "[NeMo I 2025-06-09 15:58:30 nemo_logging:393] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: INFO     :: Creating ClassifyFst grammars.\n",
      "[NeMo W 2025-06-09 15:58:43 nemo_logging:405] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n",
      "[NeMo W 2025-06-09 15:58:43 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.torch.data.TTSDataset\n",
      "      manifest_filepath: /data3/LJSpeech/nvidia_ljspeech_train.json\n",
      "      sample_rate: 22050\n",
      "      sup_data_path: /data3/LJSpeech/align_supplementary/\n",
      "      sup_data_types:\n",
      "      - align_prior_matrix\n",
      "      n_fft: 1024\n",
      "      win_length: 1024\n",
      "      hop_length: 256\n",
      "      window: hann\n",
      "      n_mels: 80\n",
      "      lowfreq: 0\n",
      "      highfreq: 8000\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      ignore_file: null\n",
      "      trim: false\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: true\n",
      "      batch_size: 64\n",
      "      num_workers: 4\n",
      "      pin_memory: false\n",
      "    \n",
      "[NeMo W 2025-06-09 15:58:43 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.torch.data.TTSDataset\n",
      "      manifest_filepath: /data3/LJSpeech/nvidia_ljspeech_val.json\n",
      "      sample_rate: 22050\n",
      "      sup_data_path: /data3/LJSpeech/align_supplementary/\n",
      "      sup_data_types:\n",
      "      - align_prior_matrix\n",
      "      n_fft: 1024\n",
      "      win_length: 1024\n",
      "      hop_length: 256\n",
      "      window: hann\n",
      "      n_mels: 80\n",
      "      lowfreq: 0\n",
      "      highfreq: 8000\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      ignore_file: null\n",
      "      trim: false\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 64\n",
      "      num_workers: 1\n",
      "      pin_memory: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-06-09 15:58:43 nemo_logging:393] PADDING: 1\n",
      "[NeMo I 2025-06-09 15:58:43 nemo_logging:393] Model AlignerModel was successfully restored from /Users/mayankanand/.cache/torch/NeMo/NeMo_2.3.1/Aligner/5b0d70eb6a09c1a8470b745034a1a00b/Aligner.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: INFO     :: Creating ClassifyFst grammars.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = TTSTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db93013-28b4-419b-b802-f4ebf2a9c017",
   "metadata": {},
   "source": [
    "### Text2Mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "855c1242-30bf-4e30-a23a-776e176e250f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text2Mel(\n",
       "  (encoder): Encoder(\n",
       "    (embedding_layer): Embedding(\n",
       "      (tok_emb): Embedding(114, 384)\n",
       "      (pos_emb): Embedding(512, 384)\n",
       "    )\n",
       "    (fft_layers): ModuleList(\n",
       "      (0-1): 2 x FFTBlock(\n",
       "        (mha): MultiHeadAttention(\n",
       "          (w_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (w_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (w_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (w_o): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm()\n",
       "        (conv1d): Conv1D(\n",
       "          (layers): Sequential(\n",
       "            (0): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): ReLU()\n",
       "            (2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (layer_norm2): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (variance_adaptor): VarianceAdaptor(\n",
       "    (duration_predictor): DurationPredictor(\n",
       "      (convolutions): ModuleList(\n",
       "        (0-1): 2 x Sequential(\n",
       "          (0): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): TransposedLayerNorm(\n",
       "            (ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (linear_proj): Linear(in_features=384, out_features=1, bias=True)\n",
       "    )\n",
       "    (lr): LengthRegulator()\n",
       "    (pitch_predictor): PitchPredictor(\n",
       "      (convolutions): ModuleList(\n",
       "        (0-1): 2 x Sequential(\n",
       "          (0): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): TransposedLayerNorm(\n",
       "            (ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (pitch_spectrogram_head): Linear(in_features=384, out_features=10, bias=True)\n",
       "      (stats_projection): Linear(in_features=384, out_features=2, bias=True)\n",
       "      (pitch_embedding): Embedding(256, 384)\n",
       "    )\n",
       "    (energy_predictor): EnergyPredictor(\n",
       "      (convolutions): ModuleList(\n",
       "        (0-1): 2 x Sequential(\n",
       "          (0): Conv1d(384, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): TransposedLayerNorm(\n",
       "            (ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (linear_proj): Linear(in_features=384, out_features=1, bias=True)\n",
       "      (energy_embedding): Embedding(256, 384)\n",
       "    )\n",
       "  )\n",
       "  (decoder): MelDecoder(\n",
       "    (fft_layers): ModuleList(\n",
       "      (0-1): 2 x FFTBlock(\n",
       "        (mha): MultiHeadAttention(\n",
       "          (w_k): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (w_q): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (w_v): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (w_o): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm()\n",
       "        (conv1d): Conv1D(\n",
       "          (layers): Sequential(\n",
       "            (0): Conv1d(384, 1536, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): ReLU()\n",
       "            (2): Conv1d(1536, 384, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (layer_norm2): LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (mel_proj): Linear(in_features=384, out_features=128, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2mel = Text2Mel(config)\n",
    "text2mel.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1de1e77-2592-406a-b03f-899f9425e3c6",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0574282-abea-4644-b0cc-d888b1092eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba81e7-8dc7-46c7-881e-3a7fd1b21c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_loop = tqdm(total=total_steps, desc=\"Training\", position=0)\n",
    "outer_loop.n = restore_step\n",
    "outer_loop.update()\n",
    "\n",
    "while True:\n",
    "    inner_loop = tqdm(total=n_epochs, desc=f\"Epoch: {epoch}\", position=1)\n",
    "\n",
    "    for batchs in feature_dataloader:\n",
    "        for batch in batchs:\n",
    "\n",
    "\n",
    "            # Model Forward\n",
    "            tokens = tokenizer.batch_tokenize(batch['raw_text'])\n",
    "            input_ids, src_mask, duration = tokens['input_ids'], tokens['mask_ids'], batch['duration']\n",
    "\n",
    "            model_output = text2mel(input_ids, src_mask, train=train, gt_duration=duration)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a777e-d86c-4ba4-8191-41ab897c8590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf7d9283-f4df-46d8-8cfd-5a25f5e1c504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 56])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['duration'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "272c8667-9196-4f06-9657-cf1e9a24fd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.batch_tokenize(batch['raw_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c9e4d92-951c-44b4-bb1a-66f66fb83cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 56]), torch.Size([4, 56]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['input_ids'].shape, tokens['mask_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a75aaa9-c9a9-4f4f-a0a3-db3687c23d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef6840-b619-42b1-a10f-c5564a796013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db67bd7-3e0b-42f0-b0b0-3253cebee45e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
